{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a647b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cpu.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661a378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Setting up the data needed\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "'dog','frog','horse','ship','truck']\n",
    "#getting data\n",
    "data_path=\"C:/Users/rosam/OneDrive/Desktop/cifar-10-batches-py\"\n",
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=True, \n",
    "                                  transform=transforms.Compose([\n",
    "                                                                transforms.ToTensor(),\n",
    "                                                                transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))]))\n",
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "#imgs.view(3, -1).mean(dim=1) => tensor([0.4914, 0.4822, 0.4465])\n",
    "#imgs.view(3, -1).std(dim=1) => tensor([0.2470, 0.2435, 0.2616])\n",
    "\n",
    "tensor_cifar10Val = datasets.CIFAR10(data_path, train=False, download=False, \n",
    "                                     transform=transforms.Compose([\n",
    "                                                                   transforms.ToTensor(),\n",
    "                                                                   transforms.Normalize((0.4942, 0.4851, 0.4504), (0.2467, 0.2429, 0.2616))]))\n",
    "imgsV = torch.stack([img_t for img_t, _ in tensor_cifar10Val], dim=3)\n",
    "#imgsV.view(3, -1).mean(dim=1) => tensor([0.4942, 0.4851, 0.4504])\n",
    "#imgsV.view(3, -1).std(dim=1) => tensor([0.2467, 0.2429, 0.2616])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b993c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining training loop\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    training_start_time = time.time()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n",
    "\n",
    "#Defining function to validate accuracy\n",
    "def validate(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3fff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Dataloader\n",
    "#used for training, shuffle and oraganize data in minibatches\n",
    "train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64,shuffle=True)\n",
    "#used for accuracy measurement\n",
    "val_loader = torch.utils.data.DataLoader(tensor_cifar10Val, batch_size=64, shuffle=False)\n",
    "acc_train_loader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a7b3940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76074, [864, 32, 9216, 32, 32, 65536, 32, 320, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 2\n",
    "#Defining model for 2a\n",
    "#ResNet block\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n",
    "#ResNet model\n",
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(*(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = ResNet10(n_chans1=32, n_blocks=10).to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2717e498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 18:47:44.718055 Epoch 1, Training loss 1.6396463077391505\n",
      "2022-03-29 19:08:10.698112 Epoch 10, Training loss 0.8880233755501945\n",
      "2022-03-29 19:31:05.550281 Epoch 20, Training loss 0.6780191484238486\n",
      "2022-03-29 19:53:44.024014 Epoch 30, Training loss 0.5455884203276671\n",
      "2022-03-29 20:20:31.746888 Epoch 40, Training loss 0.44326349448822344\n",
      "2022-03-29 20:43:41.070619 Epoch 50, Training loss 0.36229205528831543\n",
      "2022-03-29 21:05:01.381506 Epoch 60, Training loss 0.2844563014995869\n",
      "2022-03-29 21:27:21.118735 Epoch 70, Training loss 0.22482105010115278\n",
      "2022-03-29 21:48:27.650324 Epoch 80, Training loss 0.1747676111433817\n",
      "2022-03-29 22:11:20.090458 Epoch 90, Training loss 0.1432492192334417\n",
      "2022-03-29 22:36:14.902554 Epoch 100, Training loss 0.11623310760054213\n",
      "2022-03-29 23:02:24.880415 Epoch 110, Training loss 0.07888092016062849\n",
      "2022-03-29 23:25:57.217696 Epoch 120, Training loss 0.08292848738910788\n",
      "2022-03-29 23:46:50.262154 Epoch 130, Training loss 0.06526294943240597\n",
      "2022-03-30 00:13:27.192283 Epoch 140, Training loss 0.08434495080591124\n",
      "2022-03-30 00:36:22.159185 Epoch 150, Training loss 0.02275052133208031\n",
      "2022-03-30 00:59:45.859566 Epoch 160, Training loss 0.06814314946716847\n",
      "2022-03-30 01:21:41.947117 Epoch 170, Training loss 0.018641929686292195\n",
      "2022-03-30 01:40:42.903048 Epoch 180, Training loss 0.0051657248072831145\n",
      "2022-03-30 02:00:11.424748 Epoch 190, Training loss 0.007948989794134637\n",
      "2022-03-30 02:19:43.759242 Epoch 200, Training loss 0.0030590875964204463\n",
      "2022-03-30 02:39:04.586558 Epoch 210, Training loss 0.3563848157083411\n",
      "2022-03-30 02:58:26.550722 Epoch 220, Training loss 0.009543310058058438\n",
      "2022-03-30 03:17:56.440760 Epoch 230, Training loss 0.003222384857257371\n",
      "2022-03-30 03:37:23.440529 Epoch 240, Training loss 0.002568244500018125\n",
      "2022-03-30 03:56:47.257810 Epoch 250, Training loss 0.0018840118105087997\n",
      "2022-03-30 04:16:27.495196 Epoch 260, Training loss 0.0615518059932625\n",
      "2022-03-30 04:36:16.928913 Epoch 270, Training loss 0.009593826193494075\n",
      "2022-03-30 04:56:03.592072 Epoch 280, Training loss 0.002263253761722338\n",
      "2022-03-30 05:15:58.325198 Epoch 290, Training loss 0.001904034129775795\n",
      "2022-03-30 05:35:36.995744 Epoch 300, Training loss 0.0016143483096485675\n",
      "Training finished, took 38992.29s\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "training_loop(\n",
    "    n_epochs = 300,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5956c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 1.00\n",
      "Accuracy val: 0.66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 0.99984, 'val': 0.6638}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(model,  acc_train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
